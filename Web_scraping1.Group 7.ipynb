{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRmBwfMCX7Pl",
        "outputId": "b49f32e5-bf47-48da-ffac-0ecfc12475c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Write a Python program to test if a given page is found or not on the server.\n",
        "\n",
        "\n",
        "import requests\n",
        "response = requests.get(\"https://npowercanada.blackboard.com/courses/1/JDA20250T3A/content/_133969_1/scormdriver/indexAPI.html\")\n",
        "response.status_code\n",
        "response\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to extract and display all the header tags from en.wikipedia.org/wiki/Main_Page\n",
        "response = requests.get(\"https://en.wikipedia.org/wiki/Main_Page.html\")\n",
        "response.headers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JVT760VX8bG",
        "outputId": "0ddd3707-3692-48c4-d8a9-815b58001ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': 'Thu, 13 Mar 2025 16:47:42 GMT', 'server': 'mw-web.codfw.main-75dbb796cf-rmz7z', 'x-content-type-options': 'nosniff', 'content-language': 'en', 'accept-ch': '', 'vary': 'Accept-Encoding,Cookie,Authorization', 'content-type': 'text/html; charset=UTF-8', 'content-encoding': 'gzip', 'age': '0', 'x-cache': 'cp2029 miss, cp2035 miss', 'x-cache-status': 'miss', 'server-timing': 'cache;desc=\"miss\", host;desc=\"cp2035\"', 'strict-transport-security': 'max-age=106384710; includeSubDomains; preload', 'report-to': '{ \"group\": \"wm_nel\", \"max_age\": 604800, \"endpoints\": [{ \"url\": \"https://intake-logging.wikimedia.org/v1/events?stream=w3c.reportingapi.network_error&schema_uri=/w3c/reportingapi/network_error/1.0.0\" }] }', 'nel': '{ \"report_to\": \"wm_nel\", \"max_age\": 604800, \"failure_fraction\": 0.05, \"success_fraction\": 0.0}', 'set-cookie': 'WMF-Last-Access=13-Mar-2025;Path=/;HttpOnly;secure;Expires=Mon, 14 Apr 2025 12:00:00 GMT, WMF-Last-Access-Global=13-Mar-2025;Path=/;Domain=.wikipedia.org;HttpOnly;secure;Expires=Mon, 14 Apr 2025 12:00:00 GMT, GeoIP=US:IA:Council_Bluffs:41.26:-95.85:v4; Path=/; secure; Domain=.wikipedia.org, NetworkProbeLimit=0.001;Path=/;Secure;SameSite=Lax;Max-Age=3600', 'x-client-ip': '35.232.162.11', 'cache-control': 'private, s-maxage=0, max-age=0, must-revalidate, no-transform', 'transfer-encoding': 'chunked'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Python program to get 30 days of visits broken down by browser for all sites on data.gov.\n",
        "\n",
        "import requests\n",
        "\n",
        "response = requests.get(\"https://analytics.usa.gov/data/live/browsers.json\")\n",
        "\n",
        "# Parse the JSON response\n",
        "data = response.json()\n",
        "#print(data)\n",
        "# Get the total number of users\n",
        "total_users = data[\"totals\"][\"totalUsers\"]\n",
        "\n",
        "print(f\"Total users visiting U.S. government websites: {total_users}\")\n",
        "\n",
        "# Loop through browsers and visits data\n",
        "for browser, visits in data[\"totals\"][\"by_browser\"].items():\n",
        "\n",
        "    print(f\"{browser}:{visits}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5AW0QRDYknC",
        "outputId": "faaa6bac-a437-4a38-defc-c13ce93bf8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total users visiting U.S. government websites: 39976619\n",
            "Chrome:21336023\n",
            "Safari:9735069\n",
            "Edge:5806156\n",
            "Firefox:1169889\n",
            "Internet Explorer:753206\n",
            "Android Webview:339467\n",
            "Samsung Internet:325121\n",
            "Safari (in-app):283750\n",
            "Opera:144948\n",
            "Amazon Silk:38264\n",
            "YaBrowser:18521\n",
            "Mozilla Compatible Agent:16798\n",
            "Whale Browser:6193\n",
            "UC Browser:944\n",
            "Aloha Browser:335\n",
            "PaleMoon:255\n",
            "Meta Quest Browser:251\n",
            "DuckDuckGo Browser:227\n",
            "Phoenix Browser:219\n",
            "Opera Mini:219\n",
            "Android Runtime:135\n",
            "Android Browser:131\n",
            "Vivaldi:125\n",
            "Seznam:109\n",
            "SeaMonkey:82\n",
            "Iron:66\n",
            "Mozilla:47\n",
            "Maxthon:33\n",
            "Waterfox:22\n",
            "Nintendo Browser:7\n",
            "Puffin:7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qODJ7R-2jabu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Python program to get the number of people visiting a U.S. government website right now. Source: https://analytics.usa.gov/data/live/realtime.json#\n",
        "import requests\n",
        "\n",
        "response = requests.get(\"https://analytics.usa.gov/data/live/realtime.json\")\n",
        "\n",
        "# Parse the JSON response\n",
        "data2 = response.json()\n",
        "print(data2)\n",
        "#Get the total number of users\n",
        "response.headers.get(\"totals\")\n",
        "data = response.json()\n",
        "total_visitors = data2['data'][0]['activeUsers']\n",
        "total_visitors\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "eGTbKogHjRTJ",
        "outputId": "e9005d5c-1c6c-4b6f-ebe2-52fb886da729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'realtime', 'agency': None, 'query': {'metrics': [{'name': 'activeUsers'}, {'name': 'screenPageViews'}], 'limit': '10000', 'property': 'properties/397708109', 'ids': '397708109'}, 'meta': {'name': 'Active users and page views realtime', 'description': 'Number of users currently visiting all sites and the number of page views.'}, 'data': [{'activeUsers': '1962680', 'pageviews': '6041003'}], 'totals': {'activeUsers': 1962680}, 'taken_at': '2025-03-13T16:39:56.680Z'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1962680'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Python program to extract and display all the image links from en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)\n",
        "import requests\n",
        "response = requests.get(\"https://en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)\")\n",
        "response.status_code\n",
        "response\n",
        "data3 = response\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the Wikipedia page\n",
        "url = \"https://en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)\"\n",
        "\n",
        "# Send a GET request to the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content of the page using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Find all image tags on the page\n",
        "image_tags = soup.find_all(\"img\")\n",
        "\n",
        "# Extract the 'src' attribute (image URL) for each image\n",
        "image_links = []\n",
        "\n",
        "for img in image_tags:\n",
        "    img_url = img.get(\"src\")\n",
        "    if img_url:\n",
        "        # Construct the full image URL if the src is relative\n",
        "        if img_url.startswith(\"//\"):\n",
        "            img_url = \"https:\" + img_url\n",
        "        image_links.append(img_url)\n",
        "\n",
        "# Display the image links\n",
        "for link in image_links:\n",
        "    print(link)"
      ],
      "metadata": {
        "id": "hvEaoI0dhJ4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556cfac3-a5ad-42f3-d4ed-31021a833420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/static/images/icons/wikipedia.png\n",
            "/static/images/mobile/copyright/wikipedia-wordmark-en.svg\n",
            "/static/images/mobile/copyright/wikipedia-tagline-en.svg\n",
            "https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png\n",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/NlaJeffrey1942-43.jpg/220px-NlaJeffrey1942-43.jpg\n",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/008315JeffreyTurnbull1941.jpg/260px-008315JeffreyTurnbull1941.jpg\n",
            "https://upload.wikimedia.org/wikipedia/commons/e/ea/021807CameronJeffrey1941.jpg\n",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/AC0072JeffreyTruscottKittyhawks1942.jpg/280px-AC0072JeffreyTruscottKittyhawks1942.jpg\n",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIC1689Jeffrey1945.jpg/280px-VIC1689Jeffrey1945.jpg\n",
            "https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png\n",
            "https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&type=1x1&usesul3=0\n",
            "/static/images/footer/wikimedia.svg\n",
            "/w/resources/assets/mediawiki_compact.svg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Python program to display the contains of different attributes like different attributes like status_code, headers, url, history, encoding, reason, cookies, elapsed, request and content of a specified resource.\n",
        "import requests\n",
        "\n",
        "def fetch_resource_info(url):\n",
        "    try:\n",
        "        # Send a GET request to the specified URL\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Display various response attributes\n",
        "        print(f\"Status Code: {response.status_code}\")\n",
        "        print(f\"Headers: {response.headers}\")\n",
        "        print(f\"URL: {response.url}\")\n",
        "        print(f\"History: {response.history}\")\n",
        "        print(f\"Encoding: {response.encoding}\")\n",
        "        print(f\"Reason: {response.reason}\")\n",
        "        print(f\"Cookies: {response.cookies}\")\n",
        "        print(f\"Elapsed Time: {response.elapsed}\")\n",
        "        print(f\"Request Details: {response.request}\")\n",
        "        print(\"\\nContent (first 500 characters):\")\n",
        "        print(response.text[:500])  # Print first 500 characters of content\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the URL to fetch\n",
        "url = \"https://en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)\"\n",
        "fetch_resource_info(url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pofwBSm9au_8",
        "outputId": "1abeb691-9b63-4cb2-e086-62b6020841f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Headers: {'date': 'Thu, 13 Mar 2025 17:01:15 GMT', 'server': 'mw-web.codfw.main-75dbb796cf-gqpph', 'x-content-type-options': 'nosniff', 'content-language': 'en', 'accept-ch': '', 'vary': 'Accept-Encoding,Cookie,Authorization', 'last-modified': 'Wed, 12 Mar 2025 10:17:04 GMT', 'content-type': 'text/html; charset=UTF-8', 'content-encoding': 'gzip', 'age': '879', 'x-cache': 'cp2029 miss, cp2035 hit/4', 'x-cache-status': 'hit-front', 'server-timing': 'cache;desc=\"hit-front\", host;desc=\"cp2035\"', 'strict-transport-security': 'max-age=106384710; includeSubDomains; preload', 'report-to': '{ \"group\": \"wm_nel\", \"max_age\": 604800, \"endpoints\": [{ \"url\": \"https://intake-logging.wikimedia.org/v1/events?stream=w3c.reportingapi.network_error&schema_uri=/w3c/reportingapi/network_error/1.0.0\" }] }', 'nel': '{ \"report_to\": \"wm_nel\", \"max_age\": 604800, \"failure_fraction\": 0.05, \"success_fraction\": 0.0}', 'set-cookie': 'WMF-Last-Access=13-Mar-2025;Path=/;HttpOnly;secure;Expires=Mon, 14 Apr 2025 12:00:00 GMT, WMF-Last-Access-Global=13-Mar-2025;Path=/;Domain=.wikipedia.org;HttpOnly;secure;Expires=Mon, 14 Apr 2025 12:00:00 GMT, WMF-DP=bb8;Path=/;HttpOnly;secure;Expires=Fri, 14 Mar 2025 00:00:00 GMT, GeoIP=US:IA:Council_Bluffs:41.26:-95.85:v4; Path=/; secure; Domain=.wikipedia.org, NetworkProbeLimit=0.001;Path=/;Secure;SameSite=Lax;Max-Age=3600', 'x-client-ip': '35.232.162.11', 'cache-control': 'private, s-maxage=0, max-age=0, must-revalidate, no-transform', 'accept-ranges': 'bytes', 'content-length': '33100'}\n",
            "URL: https://en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)\n",
            "History: []\n",
            "Encoding: UTF-8\n",
            "Reason: OK\n",
            "Cookies: <RequestsCookieJar[<Cookie WMF-Last-Access=13-Mar-2025 for en.wikipedia.org/>, <Cookie WMF-DP=bb8 for en.wikipedia.org/>, <Cookie NetworkProbeLimit=0.001 for en.wikipedia.org/>, <Cookie WMF-Last-Access-Global=13-Mar-2025 for .wikipedia.org/>, <Cookie GeoIP=US:IA:Council_Bluffs:41.26:-95.85:v4 for .wikipedia.org/>]>\n",
            "Elapsed Time: 0:00:00.093091\n",
            "Request Details: <PreparedRequest [GET]>\n",
            "\n",
            "Content (first 500 characters):\n",
            "<!DOCTYPE html>\n",
            "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Python program to extract h1 tag from example.com.\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_h1_tag(url):\n",
        "    try:\n",
        "        # Send a GET request to the specified URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Find the first <h1> tag\n",
        "        h1_tag = soup.find(\"h1\")\n",
        "\n",
        "        # Print the content of the <h1> tag\n",
        "        if h1_tag:\n",
        "            print(f\"H1 Tag Content: {h1_tag.text.strip()}\")\n",
        "        else:\n",
        "            print(\"No <h1> tag found on the page.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Specify the URL\n",
        "url = \"http://example.com\"\n",
        "extract_h1_tag(url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoRvFQNnau2e",
        "outputId": "3d821815-aa15-46a5-9de6-a157ef8a7070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H1 Tag Content: Example Domain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Python program to get the number of datasets currently listed on data.gov.\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_dataset_count():\n",
        "    try:\n",
        "        # URL of Data.gov\n",
        "        url = \"https://catalog.data.gov/dataset\"\n",
        "\n",
        "        # Send a GET request to the page\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for bad responses (4xx, 5xx)\n",
        "\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Find the element containing the dataset count\n",
        "        count_element = soup.find(\"div\", class_=\"new-results\")\n",
        "\n",
        "        if count_element:\n",
        "            count_text = count_element.get_text(strip=True)\n",
        "            print(f\"Number of datasets listed on Data.gov: {count_text}\")\n",
        "        else:\n",
        "            print(\"Could not find the dataset count element on the page.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Run the function\n",
        "get_dataset_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0gC5lsGautQ",
        "outputId": "16a32246-0c5f-4fed-d1ec-212d1617930b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of datasets listed on Data.gov: 309,299 datasets found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRLHJ26QauYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}